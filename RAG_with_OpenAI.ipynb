{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First RAG using OpenAI API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the relevant libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test the connection to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API key\n",
    "API_KEY = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the difference between a Green Belt and a Black Belt ?\"\n",
    "sys_message = \"You are an expert in Lean Sigma.\"\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":sys_message},\n",
    "        {\"role\":\"user\", \"content\":prompt}\n",
    "    ],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In Lean Six Sigma, both Green Belts and Black Belts play crucial roles in process improvement initiatives, but they differ in terms of their responsibilities, training, and expertise. Here are the key differences:\n",
       "\n",
       "### 1. **Training and Certification:**\n",
       "   - **Green Belt:**\n",
       "     - Typically undergoes a shorter training program (usually 2-4 weeks).\n",
       "     - Focuses on the basics of Lean Six Sigma methodologies, tools, and techniques.\n",
       "     - Often certified after passing an exam that tests their understanding of fundamental concepts.\n",
       "\n",
       "   - **Black Belt:**\n",
       "     - Completes a more extensive training program (usually 4-6 months).\n",
       "     - Gains in-depth knowledge of advanced statistical tools, project management, and leadership skills.\n",
       "     - Certification usually requires passing a more comprehensive exam and demonstrating proficiency through project work.\n",
       "\n",
       "### 2. **Role and Responsibilities:**\n",
       "   - **Green Belt:**\n",
       "     - Works on process improvement projects part-time while maintaining their primary job responsibilities.\n",
       "     - Typically leads smaller projects or assists Black Belts in larger projects.\n",
       "     - Focuses on data collection, analysis, and implementing solutions within their area of expertise.\n",
       "\n",
       "   - **Black Belt:**\n",
       "     - Works on process improvement projects full-time and often leads larger, more complex projects.\n",
       "     - Trains and mentors Green Belts and other team members in Lean Six Sigma methodologies.\n",
       "     - Responsible for project management, ensuring that projects align with organizational goals, and delivering measurable results.\n",
       "\n",
       "### 3. **Statistical Knowledge:**\n",
       "   - **Green Belt:**\n",
       "     - Has a basic understanding of statistical tools and techniques, such as process mapping, root cause analysis, and basic hypothesis testing.\n",
       "     - Uses these tools to support project work and data analysis.\n",
       "\n",
       "   - **Black Belt:**\n",
       "     - Possesses advanced statistical knowledge and is proficient in using complex tools such as regression analysis, design of experiments (DOE), and multivariate analysis.\n",
       "     - Capable of interpreting data and making data-driven decisions to drive significant improvements.\n",
       "\n",
       "### 4. **Project Scope:**\n",
       "   - **Green Belt:**\n",
       "     - Typically works on projects that have a limited scope and impact, often within a specific department or function.\n",
       "     - Focuses on incremental improvements.\n",
       "\n",
       "   - **Black Belt:**\n",
       "     - Engages in projects that have a broader organizational impact and strategic significance.\n",
       "     - Aims for transformational changes that can lead to substantial cost savings and efficiency gains.\n",
       "\n",
       "### 5. **Leadership and Influence:**\n",
       "   - **Green Belt:**\n",
       "     - May have some leadership responsibilities but generally operates under the guidance of Black Belts or higher-level management.\n",
       "     - Influences change within their immediate team or department.\n",
       "\n",
       "   - **Black Belt:**\n",
       "     - Acts as a leader and change agent within the organization.\n",
       "     - Has a greater influence on strategic decisions and can drive cultural change towards continuous improvement.\n",
       "\n",
       "In summary, while both Green Belts and Black Belts are essential to Lean Six Sigma initiatives, Black Belts have a deeper level of expertise, broader responsibilities, and a more significant role in leading and managing improvement projects."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare the data\n",
    "\n",
    "Our date is in the form of PDF files. In order to have good performance for our information extraction using the LLM, we need to transform them into images.\n",
    "\n",
    "This is what we are going to do next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Grabing the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the folder pdf_files\n"
     ]
    }
   ],
   "source": [
    "# Grab the current directory \n",
    "current_directory = Path.cwd()\n",
    "\n",
    "# check for the pdf folder\n",
    "pdf_folder = \"pdf_files\"\n",
    "for item in current_directory.iterdir():\n",
    "    if item.is_dir() and item.name == pdf_folder:\n",
    "        print(f\"Found the folder {pdf_folder}\")\n",
    "        break\n",
    "    print(\"No directory as mentionned found ....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the files\n",
    "path_to_files = current_directory /pdf_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The white house cookbook.pdf',\n",
       " 'The chinese cookbook.pdf',\n",
       " 'Things mother used to make.pdf',\n",
       " 'Southern Cookbook of Fine Recipes.pdf',\n",
       " 'The Italian cookbook.pdf']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop through the folder and graph the pdf file names \n",
    "list_files = [file.name for file in path_to_files.iterdir()]\n",
    "list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the one that interest me \n",
    "file_name = list_files[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Converting the files\n",
    "\n",
    "Let's create a function that takes our pdf location and return a folder containing the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the entire path\n",
    "path = path_to_files / file_name\n",
    "output_foler = \"images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_image(image_path=path, output = output_foler):\n",
    "    output_folder = Path(\".\") / output\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "    images_path = list()\n",
    "    images = convert_from_path(pdf_path=image_path.as_posix())\n",
    "    for idx, image in enumerate(images, start=1):\n",
    "        #img_path = os.path.join(image_path, f\"page_{idx}.jpg\")\n",
    "        img_path = output_folder / f\"page_{idx}.jpg\"\n",
    "        image.save(img_path.as_posix())\n",
    "        images_path.append(img_path.as_posix())\n",
    "    return images_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = convert_to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract the data\n",
    "\n",
    "We will use the GPT model `gtp-4o-mini`to extract the data\n",
    "\n",
    "First, we will propose a prompt (as `sys_message`for the LLM) in order to get most of our extraction. Then we will extract the information from the pages and store it in a dictionnary (two keys: the `img_path`, the `img_content`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Prompt engineering for system message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_message = \"\"\"\n",
    "Please analyze the content of this image and extract any related recipe information into structured component.\n",
    "Specifically, extract the recipe title, list of ingredients and step by step instructions, cuisine type, dish type,\n",
    "and any relevant tags or metadata.\n",
    "The output must be formation in a way suited for embedding in a Retrival Augmented Generation (RAG) system.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Please proceed by extracting the information as required\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Extract the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a function to call the OpenAI API\n",
    "\n",
    "def ask_gpt(img_data, model=MODEL, prompt=user_prompt, sys_message=sys_message):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\":\"system\", \"content\":sys_message},\n",
    "            {\"role\":\"user\", \"content\":[\n",
    "                {\"type\":\"text\", \"text\":prompt},\n",
    "                {\"type\":\"image_url\", \"image_url\":{\"url\":f\"data:image/jpeg;base64,{img_data}\"}}\n",
    "            ]}\n",
    "        ],\n",
    "        temperature = 0\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For this we will be using the `images_path`list previously used, and pass each image one by one to the gpt model.\n",
    "\n",
    "Before, we would be needing to encode it in a base64 format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let create a function for the encoding\n",
    "import base64\n",
    "\n",
    "def encode_base64(img_path):\n",
    "    with open(img_path, mode=\"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images/page_1.jpg ...\n",
      "Ending processing images/page_1.jpg...\n",
      "Processing images/page_2.jpg ...\n",
      "Ending processing images/page_2.jpg...\n",
      "Processing images/page_3.jpg ...\n",
      "Ending processing images/page_3.jpg...\n",
      "Processing images/page_4.jpg ...\n",
      "Ending processing images/page_4.jpg...\n",
      "Processing images/page_5.jpg ...\n",
      "Ending processing images/page_5.jpg...\n",
      "Processing images/page_6.jpg ...\n",
      "Ending processing images/page_6.jpg...\n",
      "Processing images/page_7.jpg ...\n",
      "Ending processing images/page_7.jpg...\n",
      "Processing images/page_8.jpg ...\n",
      "Ending processing images/page_8.jpg...\n",
      "Processing images/page_9.jpg ...\n",
      "Ending processing images/page_9.jpg...\n",
      "Processing images/page_10.jpg ...\n",
      "Ending processing images/page_10.jpg...\n",
      "Processing images/page_11.jpg ...\n",
      "Ending processing images/page_11.jpg...\n",
      "Processing images/page_12.jpg ...\n",
      "Ending processing images/page_12.jpg...\n",
      "Processing images/page_13.jpg ...\n",
      "Ending processing images/page_13.jpg...\n",
      "Processing images/page_14.jpg ...\n",
      "Ending processing images/page_14.jpg...\n",
      "Processing images/page_15.jpg ...\n",
      "Ending processing images/page_15.jpg...\n",
      "Processing images/page_16.jpg ...\n",
      "Ending processing images/page_16.jpg...\n",
      "Processing images/page_17.jpg ...\n",
      "Ending processing images/page_17.jpg...\n",
      "Processing images/page_18.jpg ...\n",
      "Ending processing images/page_18.jpg...\n",
      "Processing images/page_19.jpg ...\n",
      "Ending processing images/page_19.jpg...\n",
      "Processing images/page_20.jpg ...\n",
      "Ending processing images/page_20.jpg...\n",
      "Processing images/page_21.jpg ...\n",
      "Ending processing images/page_21.jpg...\n",
      "Processing images/page_22.jpg ...\n",
      "Ending processing images/page_22.jpg...\n",
      "Processing images/page_23.jpg ...\n",
      "Ending processing images/page_23.jpg...\n",
      "Processing images/page_24.jpg ...\n",
      "Ending processing images/page_24.jpg...\n",
      "Processing images/page_25.jpg ...\n",
      "Ending processing images/page_25.jpg...\n",
      "Processing images/page_26.jpg ...\n",
      "Ending processing images/page_26.jpg...\n",
      "Processing images/page_27.jpg ...\n",
      "Ending processing images/page_27.jpg...\n",
      "Processing images/page_28.jpg ...\n",
      "Ending processing images/page_28.jpg...\n",
      "Processing images/page_29.jpg ...\n",
      "Ending processing images/page_29.jpg...\n",
      "Processing images/page_30.jpg ...\n",
      "Ending processing images/page_30.jpg...\n",
      "Processing images/page_31.jpg ...\n",
      "Ending processing images/page_31.jpg...\n",
      "Processing images/page_32.jpg ...\n",
      "Ending processing images/page_32.jpg...\n",
      "Processing images/page_33.jpg ...\n",
      "Ending processing images/page_33.jpg...\n",
      "Processing images/page_34.jpg ...\n",
      "Ending processing images/page_34.jpg...\n",
      "Processing images/page_35.jpg ...\n",
      "Ending processing images/page_35.jpg...\n",
      "Processing images/page_36.jpg ...\n",
      "Ending processing images/page_36.jpg...\n",
      "Processing images/page_37.jpg ...\n",
      "Ending processing images/page_37.jpg...\n",
      "Processing images/page_38.jpg ...\n",
      "Ending processing images/page_38.jpg...\n",
      "Processing images/page_39.jpg ...\n",
      "Ending processing images/page_39.jpg...\n",
      "Processing images/page_40.jpg ...\n",
      "Ending processing images/page_40.jpg...\n",
      "Processing images/page_41.jpg ...\n",
      "Ending processing images/page_41.jpg...\n",
      "Processing images/page_42.jpg ...\n",
      "Ending processing images/page_42.jpg...\n",
      "Processing images/page_43.jpg ...\n",
      "Ending processing images/page_43.jpg...\n",
      "Processing images/page_44.jpg ...\n",
      "Ending processing images/page_44.jpg...\n",
      "Processing images/page_45.jpg ...\n",
      "Ending processing images/page_45.jpg...\n",
      "Processing images/page_46.jpg ...\n",
      "Ending processing images/page_46.jpg...\n",
      "Processing images/page_47.jpg ...\n",
      "Ending processing images/page_47.jpg...\n",
      "Processing images/page_48.jpg ...\n",
      "Ending processing images/page_48.jpg...\n",
      "Processing images/page_49.jpg ...\n",
      "Ending processing images/page_49.jpg...\n",
      "Processing images/page_50.jpg ...\n",
      "Ending processing images/page_50.jpg...\n",
      "Processing images/page_51.jpg ...\n",
      "Ending processing images/page_51.jpg...\n",
      "Processing images/page_52.jpg ...\n",
      "Ending processing images/page_52.jpg...\n",
      "Processing images/page_53.jpg ...\n",
      "Ending processing images/page_53.jpg...\n",
      "Processing images/page_54.jpg ...\n",
      "Ending processing images/page_54.jpg...\n",
      "Processing images/page_55.jpg ...\n",
      "Ending processing images/page_55.jpg...\n",
      "Processing images/page_56.jpg ...\n",
      "Ending processing images/page_56.jpg...\n",
      "Processing images/page_57.jpg ...\n",
      "Ending processing images/page_57.jpg...\n",
      "Processing images/page_58.jpg ...\n",
      "Ending processing images/page_58.jpg...\n",
      "Processing images/page_59.jpg ...\n",
      "Ending processing images/page_59.jpg...\n",
      "Processing images/page_60.jpg ...\n",
      "Ending processing images/page_60.jpg...\n",
      "Processing images/page_61.jpg ...\n",
      "Ending processing images/page_61.jpg...\n",
      "Processing images/page_62.jpg ...\n",
      "Ending processing images/page_62.jpg...\n",
      "Processing images/page_63.jpg ...\n",
      "Ending processing images/page_63.jpg...\n",
      "Processing images/page_64.jpg ...\n",
      "Ending processing images/page_64.jpg...\n",
      "Processing images/page_65.jpg ...\n",
      "Ending processing images/page_65.jpg...\n",
      "Processing images/page_66.jpg ...\n",
      "Ending processing images/page_66.jpg...\n",
      "Processing images/page_67.jpg ...\n",
      "Ending processing images/page_67.jpg...\n",
      "Processing images/page_68.jpg ...\n",
      "Ending processing images/page_68.jpg...\n",
      "Processing images/page_69.jpg ...\n",
      "Ending processing images/page_69.jpg...\n",
      "Processing images/page_70.jpg ...\n",
      "Ending processing images/page_70.jpg...\n",
      "Processing images/page_71.jpg ...\n",
      "Ending processing images/page_71.jpg...\n",
      "Processing images/page_72.jpg ...\n",
      "Ending processing images/page_72.jpg...\n",
      "Processing images/page_73.jpg ...\n",
      "Ending processing images/page_73.jpg...\n",
      "Processing images/page_74.jpg ...\n",
      "Ending processing images/page_74.jpg...\n",
      "Processing images/page_75.jpg ...\n",
      "Ending processing images/page_75.jpg...\n",
      "Processing images/page_76.jpg ...\n",
      "Ending processing images/page_76.jpg...\n",
      "Processing images/page_77.jpg ...\n",
      "Ending processing images/page_77.jpg...\n",
      "Processing images/page_78.jpg ...\n",
      "Ending processing images/page_78.jpg...\n",
      "Processing images/page_79.jpg ...\n",
      "Ending processing images/page_79.jpg...\n",
      "Processing images/page_80.jpg ...\n",
      "Ending processing images/page_80.jpg...\n",
      "Processing images/page_81.jpg ...\n",
      "Ending processing images/page_81.jpg...\n",
      "Processing images/page_82.jpg ...\n",
      "Ending processing images/page_82.jpg...\n",
      "Processing images/page_83.jpg ...\n",
      "Ending processing images/page_83.jpg...\n",
      "Processing images/page_84.jpg ...\n",
      "Ending processing images/page_84.jpg...\n",
      "Processing images/page_85.jpg ...\n",
      "Ending processing images/page_85.jpg...\n",
      "Processing images/page_86.jpg ...\n",
      "Ending processing images/page_86.jpg...\n",
      "Processing images/page_87.jpg ...\n",
      "Ending processing images/page_87.jpg...\n",
      "Processing images/page_88.jpg ...\n",
      "Ending processing images/page_88.jpg...\n",
      "Processing images/page_89.jpg ...\n",
      "Ending processing images/page_89.jpg...\n",
      "Processing images/page_90.jpg ...\n",
      "Ending processing images/page_90.jpg...\n",
      "Processing images/page_91.jpg ...\n",
      "Ending processing images/page_91.jpg...\n",
      "Processing images/page_92.jpg ...\n",
      "Ending processing images/page_92.jpg...\n",
      "Processing images/page_93.jpg ...\n",
      "Ending processing images/page_93.jpg...\n",
      "Processing images/page_94.jpg ...\n",
      "Ending processing images/page_94.jpg...\n",
      "Processing images/page_95.jpg ...\n",
      "Ending processing images/page_95.jpg...\n",
      "Processing images/page_96.jpg ...\n",
      "Ending processing images/page_96.jpg...\n",
      "Processing images/page_97.jpg ...\n",
      "Ending processing images/page_97.jpg...\n",
      "Processing images/page_98.jpg ...\n",
      "Ending processing images/page_98.jpg...\n",
      "Processing images/page_99.jpg ...\n",
      "Ending processing images/page_99.jpg...\n",
      "Processing images/page_100.jpg ...\n",
      "Ending processing images/page_100.jpg...\n",
      "Processing images/page_101.jpg ...\n",
      "Ending processing images/page_101.jpg...\n",
      "Processing images/page_102.jpg ...\n",
      "Ending processing images/page_102.jpg...\n",
      "Processing images/page_103.jpg ...\n",
      "Ending processing images/page_103.jpg...\n",
      "Processing images/page_104.jpg ...\n",
      "Ending processing images/page_104.jpg...\n",
      "Processing images/page_105.jpg ...\n",
      "Ending processing images/page_105.jpg...\n",
      "Processing images/page_106.jpg ...\n",
      "Ending processing images/page_106.jpg...\n",
      "Processing images/page_107.jpg ...\n",
      "Ending processing images/page_107.jpg...\n",
      "Processing images/page_108.jpg ...\n",
      "Ending processing images/page_108.jpg...\n",
      "Processing images/page_109.jpg ...\n",
      "Ending processing images/page_109.jpg...\n",
      "Processing images/page_110.jpg ...\n",
      "Ending processing images/page_110.jpg...\n",
      "Processing images/page_111.jpg ...\n",
      "Ending processing images/page_111.jpg...\n",
      "Processing images/page_112.jpg ...\n",
      "Ending processing images/page_112.jpg...\n",
      "Processing images/page_113.jpg ...\n",
      "Ending processing images/page_113.jpg...\n",
      "Processing images/page_114.jpg ...\n",
      "Ending processing images/page_114.jpg...\n",
      "Processing images/page_115.jpg ...\n",
      "Ending processing images/page_115.jpg...\n",
      "Processing images/page_116.jpg ...\n",
      "Ending processing images/page_116.jpg...\n",
      "Processing images/page_117.jpg ...\n",
      "Ending processing images/page_117.jpg...\n",
      "Processing images/page_118.jpg ...\n",
      "Ending processing images/page_118.jpg...\n",
      "Processing images/page_119.jpg ...\n",
      "Ending processing images/page_119.jpg...\n",
      "Processing images/page_120.jpg ...\n",
      "Ending processing images/page_120.jpg...\n",
      "Processing images/page_121.jpg ...\n",
      "Ending processing images/page_121.jpg...\n",
      "Processing images/page_122.jpg ...\n",
      "Ending processing images/page_122.jpg...\n",
      "Processing images/page_123.jpg ...\n",
      "Ending processing images/page_123.jpg...\n",
      "Processing images/page_124.jpg ...\n",
      "Ending processing images/page_124.jpg...\n",
      "Processing images/page_125.jpg ...\n",
      "Ending processing images/page_125.jpg...\n",
      "Processing images/page_126.jpg ...\n",
      "Ending processing images/page_126.jpg...\n",
      "Processing images/page_127.jpg ...\n",
      "Ending processing images/page_127.jpg...\n",
      "Processing images/page_128.jpg ...\n",
      "Ending processing images/page_128.jpg...\n",
      "Processing images/page_129.jpg ...\n",
      "Ending processing images/page_129.jpg...\n",
      "Processing images/page_130.jpg ...\n",
      "Ending processing images/page_130.jpg...\n",
      "Processing images/page_131.jpg ...\n",
      "Ending processing images/page_131.jpg...\n",
      "Processing images/page_132.jpg ...\n",
      "Ending processing images/page_132.jpg...\n",
      "Processing images/page_133.jpg ...\n",
      "Ending processing images/page_133.jpg...\n",
      "Processing images/page_134.jpg ...\n",
      "Ending processing images/page_134.jpg...\n",
      "Processing images/page_135.jpg ...\n",
      "Ending processing images/page_135.jpg...\n",
      "Processing images/page_136.jpg ...\n",
      "Ending processing images/page_136.jpg...\n",
      "Processing ended !\n"
     ]
    }
   ],
   "source": [
    "# Extract the informtion using GPT\n",
    "content = list()\n",
    "for img_path in images_path:\n",
    "    print(f\"Processing {img_path} ...\")\n",
    "    img_data = encode_base64(img_path=img_path)\n",
    "    answer = ask_gpt(img_data=img_data)\n",
    "    content.append({\"image_path\":img_path,\"info\":answer})\n",
    "    print(f\"Ending processing {img_path}...\")\n",
    "print(\"Processing ended !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_path': 'images/page_44.jpg',\n",
       " 'info': 'Here is the extracted recipe information structured for a Retrieval Augmented Generation (RAG) system:\\n\\n### Recipe Title\\n- Butter Scotch\\n\\n### Ingredients\\n- ½ Cupful of Molasses\\n- ½ Cupful of Butter\\n- ½ Cupful of Sugar\\n\\n### Instructions\\n1. Boil until it strings.\\n2. Pour into a buttered tin.\\n3. When cold, break into pieces. This is very nice when cooled on snow.\\n\\n---\\n\\n### Recipe Title\\n- Pop Corn Balls (very old recipe)\\n\\n### Ingredients\\n- 1 Cupful of Molasses\\n- Piece of Butter, half the size of an Egg\\n- Pinch of soda\\n- 1 quart dish full of popped corn\\n\\n### Instructions\\n1. Boil together until it strings.\\n2. Stir in a pinch of soda.\\n3. Put this over a quart dish full of popped corn.\\n4. When cool enough to handle, squeeze into balls the size of an orange.\\n\\n### Cuisine Type\\n- Traditional American\\n\\n### Dish Type\\n- Candy / Snack\\n\\n### Tags/Metadata\\n- Old-fashioned recipes\\n- Sweet treats\\n- Homemade candy\\n- Family recipes'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how the data look like\n",
    "from random import choice\n",
    "example = choice(content)\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the extracted recipe information structured for a Retrieval Augmented Generation (RAG) system:\n",
       "\n",
       "### Recipe Title\n",
       "- Butter Scotch\n",
       "\n",
       "### Ingredients\n",
       "- ½ Cupful of Molasses\n",
       "- ½ Cupful of Butter\n",
       "- ½ Cupful of Sugar\n",
       "\n",
       "### Instructions\n",
       "1. Boil until it strings.\n",
       "2. Pour into a buttered tin.\n",
       "3. When cold, break into pieces. This is very nice when cooled on snow.\n",
       "\n",
       "---\n",
       "\n",
       "### Recipe Title\n",
       "- Pop Corn Balls (very old recipe)\n",
       "\n",
       "### Ingredients\n",
       "- 1 Cupful of Molasses\n",
       "- Piece of Butter, half the size of an Egg\n",
       "- Pinch of soda\n",
       "- 1 quart dish full of popped corn\n",
       "\n",
       "### Instructions\n",
       "1. Boil together until it strings.\n",
       "2. Stir in a pinch of soda.\n",
       "3. Put this over a quart dish full of popped corn.\n",
       "4. When cool enough to handle, squeeze into balls the size of an orange.\n",
       "\n",
       "### Cuisine Type\n",
       "- Traditional American\n",
       "\n",
       "### Dish Type\n",
       "- Candy / Snack\n",
       "\n",
       "### Tags/Metadata\n",
       "- Old-fashioned recipes\n",
       "- Sweet treats\n",
       "- Homemade candy\n",
       "- Family recipes"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the data \n",
    "display(Markdown(example[\"info\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data\n",
    "\n",
    "In this section we will remove the unecessary information before embedding and indexing.\n",
    "\n",
    "In our case we are dealing with recipes. So the relevant information is:\n",
    "\n",
    "- ingredients\n",
    "- recipe name\n",
    "- instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_path': 'images/page_9.jpg', 'info': 'Based on the provided text, here is the structured information extracted:\\n\\n### Recipe Information\\n\\n- **Title**: The Things Mother Used To Make\\n- **Cuisine Type**: Traditional/New England\\n- **Dish Type**: Old-fashioned recipes\\n- **Introduction**: \\n  - The recipes have been handed down through generations for nearly a hundred years.\\n  - The author, a New England woman, has tested these recipes in her kitchen.\\n  - The material was originally published in *Suburban Life* and has been preserved in book form.\\n\\n### Metadata\\n- **Author**: Frank A. Arnold\\n- **Publication Date**: September 15, 1913\\n- **Series**: Countryside Manuals\\n\\n### Tags\\n- Traditional recipes\\n- Family recipes\\n- Historical cooking\\n\\nThis format is suitable for embedding in a Retrieval Augmented Generation (RAG) system.'} is not relevant ...\n",
      "{'image_path': 'images/page_10.jpg', 'info': \"I'm unable to extract any information from the image as it appears to be blank. If you have another image or text, please share it, and I'll be happy to assist!\"} is not relevant ...\n",
      "{'image_path': 'images/page_12.jpg', 'info': \"I'm unable to extract any information from the image as it appears to be blank. If you have another image or text, please share it, and I'll be happy to assist!\"} is not relevant ...\n",
      "{'image_path': 'images/page_15.jpg', 'info': 'Here’s the extracted information from the provided content:\\n\\n### Recipe Information\\n\\n- **Cuisine Type**: American\\n- **Dish Type**: Various (Desserts, Eggs, Fish, Meat Dishes)\\n\\n### Recipes List\\n\\n1. **Baked Apples, No. 2**\\n   - **Page**: 23\\n\\n2. **Baked Sweet Apples**\\n   - **Page**: 24\\n\\n3. **Baked Apple Dumplings**\\n   - **Page**: 24\\n\\n4. **Fried Apples**\\n   - **Page**: 24\\n\\n5. **Bramberries**\\n   - **Page**: 25\\n\\n6. **Cream Puffs**\\n   - **Page**: 25\\n\\n7. **Floating Island**\\n   - **Page**: 26\\n\\n8. **Huckleberry Dumplings**\\n   - **Page**: 26\\n\\n9. **Coffee Jelly**\\n   - **Page**: 27\\n\\n10. **Lemon Jelly**\\n    - **Page**: 27\\n\\n11. **Strawberry Shortcake, No. 1**\\n    - **Page**: 28\\n\\n12. **Strawberry Shortcake, No. 2**\\n    - **Page**: 28\\n\\n13. **To Boil Eggs**\\n    - **Page**: 29\\n\\n14. **Eggs on Toast**\\n    - **Page**: 29\\n\\n15. **Plain Omelette**\\n    - **Page**: 29\\n\\n16. **Ham Omelette**\\n    - **Page**: 30\\n\\n17. **New England Poached Eggs**\\n    - **Page**: 30\\n\\n18. **Clam Fritters**\\n    - **Page**: 31\\n\\n19. **Fish Balls**\\n    - **Page**: 31\\n\\n20. **To Boil a Lobster**\\n    - **Page**: 31\\n\\n21. **To Dress Lobsters Cold**\\n    - **Page**: 32\\n\\n22. **Baked Mackerel**\\n    - **Page**: 32\\n\\n23. **Oysters on Toast**\\n    - **Page**: 33\\n\\n24. **Baked Shad**\\n    - **Page**: 33\\n\\n25. **A La Mode Beef**\\n    - **Page**: 34\\n\\n26. **Beefsteak Pie**\\n    - **Page**: 34\\n\\n27. **Beef Stew with Dumplings**\\n    - **Page**: 35\\n\\n### Relevant Tags/Metadata\\n- **Tags**: Desserts, Eggs, Seafood, Meat Dishes, American Cuisine\\n\\nThis structured information can be used for embedding in a Retrieval Augmented Generation (RAG) system.'} is not relevant ...\n",
      "{'image_path': 'images/page_17.jpg', 'info': 'Based on the content provided, here is the structured information extracted:\\n\\n### Recipe Information\\n\\n- **Cuisine Type**: American\\n- **Dish Type**: Various (Pies, Preserves)\\n- **Recipes**:\\n  1. **Title**: Piccalilli, No. 1\\n     - **Page**: 49\\n  2. **Title**: Piccalilli, No. 2\\n     - **Page**: 49\\n  3. **Title**: Piccalilli, No. 3\\n     - **Page**: 50\\n  4. **Title**: Tomato Catsup, No. 1\\n     - **Page**: 50\\n  5. **Title**: Tomato Catsup, No. 2\\n     - **Page**: 51\\n  6. **Title**: Pickled Watermelon Rind\\n     - **Page**: 51\\n  7. **Title**: Rich Pie Crust\\n     - **Page**: 52\\n  8. **Title**: Pork Apple Pie\\n     - **Page**: 52\\n  9. **Title**: Chocolate Custard Pie\\n     - **Page**: 52\\n  10. **Title**: Cocoanut Pie\\n      - **Page**: 53\\n  11. **Title**: Cranberry Pie\\n      - **Page**: 53\\n  12. **Title**: Cream Pie\\n      - **Page**: 54\\n  13. **Title**: Old-Time Custard Pie\\n      - **Page**: 54\\n  14. **Title**: Frosted Lemon Pie\\n      - **Page**: 54\\n  15. **Title**: Mock Mince Pie\\n      - **Page**: 55\\n  16. **Title**: Pumpkin Pie, No. 1\\n      - **Page**: 55\\n  17. **Title**: Pumpkin Pie, No. 2\\n      - **Page**: 56\\n  18. **Title**: Rhubarb Pie\\n      - **Page**: 56\\n  19. **Title**: Rolley Polys\\n      - **Page**: 56\\n  20. **Title**: Squash Pie\\n      - **Page**: 57\\n  21. **Title**: Cream Washington Pies\\n      - **Page**: 57\\n  22. **Title**: Cream for Filling\\n      - **Page**: 58\\n  23. **Title**: Crab Apple Jelly\\n      - **Page**: 59\\n  24. **Title**: California Jam\\n      - **Page**: 59\\n  25. **Title**: Canned Cherries\\n      - **Page**: 59\\n  26. **Title**: Cherry Conserve\\n      - **Page**: 60\\n  27. **Title**: Preserved Citron\\n      - **Page**: 60\\n  28. **Title**: Currant Jelly\\n      - **Page**: 61\\n  29. **Title**: Spiced Currants\\n      - **Page**: 61\\n\\n### Relevant Tags/Metadata\\n- **Tags**: Preserves, Pies, Condiments, Desserts, American Cuisine\\n\\nThis structured format can be utilized for embedding in a Retrieval Augmented Generation (RAG) system.'} is not relevant ...\n",
      "{'image_path': 'images/page_18.jpg', 'info': \"Here’s the extracted information from the provided content:\\n\\n### Recipe Information\\n\\n- **Cuisine Type**: Preserves and Puddings\\n- **Dish Type**: Various (Jams, Jellies, Puddings)\\n- **Tags/Metadata**: \\n  - Preserves\\n  - Jams\\n  - Jellies\\n  - Puddings\\n  - Canning\\n  - Fruit Preservation\\n\\n### Recipes Listed\\n\\n1. **Cranberry Jelly**\\n2. **Grape Conserve**\\n3. **Grape Marmalade**\\n4. **Grape Preserve**\\n5. **Orange Marmalade**\\n6. **Peach Marmalade**\\n7. **To Can Peaches**\\n8. **Pickled Peaches**\\n9. **Ginger Pears**\\n10. **Preserved Pears**\\n11. **Way to Pickle Pears**\\n12. **To Preserve Pineapple**\\n13. **Quince Jelly**\\n14. **Quince Marmalade**\\n15. **Quince Sauce**\\n16. **Raspberry Jam, No. 1**\\n17. **Raspberry Jam, No. 2**\\n18. **To Keep Rhubarb Through the Winter**\\n19. **Rhubarb Marmalade**\\n20. **Rhubarb Jam**\\n21. **Spiced Fruit**\\n\\n### Puddings Listed\\n\\n1. **Bread Pudding**\\n2. **Steamed Chocolate Pudding**\\n3. **Graham Pudding**\\n4. **Hasty Pudding**\\n5. **Baked Indian Pudding**\\n6. **Orange Pudding**\\n7. **Plum Pudding**\\n8. **Queen's Pudding**\\n9. **Poor Man's Rice Pudding**\\n10. **Suet Pudding**\\n11. **Tapioca Cream**\\n\\nThis structured information can be used for embedding in a Retrieval Augmented Generation (RAG) system.\"} is not relevant ...\n",
      "{'image_path': 'images/page_20.jpg', 'info': \"I'm unable to extract any information from the image as it appears to be blank. If you have another image or text, please share it, and I'll be happy to assist!\"} is not relevant ...\n",
      "{'image_path': 'images/page_22.jpg', 'info': \"I'm unable to extract any information from the image as it appears to be blank. If you have another image or text, please share it, and I'll be happy to assist!\"} is not relevant ...\n",
      "{'image_path': 'images/page_106.jpg', 'info': \"I'm unable to extract any information from the image as it appears to be blank. If you have another image or text, please share it, and I'll be happy to assist!\"} is not relevant ...\n",
      "{'image_path': 'images/page_107.jpg', 'info': 'I\\'m unable to extract any recipe information from the image you provided, as it appears to be a blank page with the word \"APPENDIX\" on it. If you have another image or specific content you\\'d like me to analyze, please share!'} is not relevant ...\n",
      "{'image_path': 'images/page_108.jpg', 'info': \"I'm unable to extract any information from the image as it appears to be blank. If you have another image or text, please share it, and I'll be happy to assist!\"} is not relevant ...\n",
      "{'image_path': 'images/page_133.jpg', 'info': \"I'm unable to extract any information from the image as it appears to be blank. If you have another image or text, please share it, and I'll be happy to assist!\"} is not relevant ...\n",
      "{'image_path': 'images/page_134.jpg', 'info': \"I'm unable to extract any information from the image as it appears to be blank. If you have another image or text, please share it, and I'll be happy to assist!\"} is not relevant ...\n",
      "{'image_path': 'images/page_135.jpg', 'info': \"I'm unable to extract any information from the image as it appears to be blank. If you have another image or text, please share it, and I'll be happy to assist!\"} is not relevant ...\n",
      "{'image_path': 'images/page_136.jpg', 'info': \"I'm unable to extract any information from the image provided. If you have text or details about a recipe, feel free to share, and I can help organize that information!\"} is not relevant ...\n"
     ]
    }
   ],
   "source": [
    "# Filter the recipe information\n",
    "filtered_recipe = list()\n",
    "keyword_list = [\"ingredients\",\"instructions\",\"recipe title\"]\n",
    "for recipe in content:\n",
    "    if any(keyword in recipe[\"info\"].lower() for keyword in keyword_list):\n",
    "        filtered_recipe.append(recipe)\n",
    "    else:\n",
    "        print(f\"{recipe} is not relevant ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # to store our cleaned data and allows for reload in case of crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = Path.cwd() / \"output_data.json\"\n",
    "with open(output_data.as_posix(), mode=\"w\") as json_file:\n",
    "    json.dump(filtered_recipe, json_file, indent=4) # indent = 4 for formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the recipes just in case\n",
    "def load_data(file_name = \"./output_data.json\", load=False):\n",
    "\tif load:\n",
    "\t\twith open(file_name, mode=\"r\") as json_file:\n",
    "\t\t\tfiltered_recipes = json.load(json_file)\n",
    "\treturn filtered_recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_recipes = load_data(load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embedding for each recipe\n",
    "recipe_texts = [recipe[\"info\"] for recipe in filtered_recipes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_response = client.embeddings.create(\n",
    "\tinput = recipe_texts,\n",
    "\tmodel = \"text-embedding-3-large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the embeddings \n",
    "embedding = [data.embedding for data in embedding_response.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to improve the efficiency when feeding the embedding to our retriever, we will convert the embedding into numpy array\n",
    "\n",
    "embedding_matrix = np.array(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the index (using FAISS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the index\n",
    "index = faiss.IndexFlatL2(embedding_matrix.shape[1])\n",
    "# add the embedding to the index\n",
    "index.add(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the index (good thing to do when working with large data)\n",
    "faiss.write_index(index, \"filtered_recipes_index.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the metadata\n",
    "metadata = [{\"recipe_info\":recipe[\"info\"],\n",
    "\t\t\t\t\t\t\"image_path\":recipe[\"image_path\"]} for recipe in filtered_recipes]\n",
    "\n",
    "with open(\"recipe_metadata.json\", mode=\"w\") as json_file:\n",
    "\tjson.dump(metadata, json_file, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to query the embeddings\n",
    "def query_embeddings(query, index, metadata, k=5):\n",
    "\t# Generate the embeddings for the query\n",
    "\tquery_embedding = client.embeddings.create(\n",
    "\t\tinput = [query],\n",
    "\t\tmodel = \"text-embedding-3-large\"\n",
    "\t).data[0].embedding\n",
    "\tquery_vector = np.array(query_embedding).reshape(1,-1)\n",
    "\t# Search the FAISS index\n",
    "\tdistances, indices = index.search(query_vector, min(k,len(metadata)))\n",
    "\t# Store the indices and distances\n",
    "\tstored_indices = indices[0].tolist()\n",
    "\tstored_distances = distances[0].tolist()\n",
    "\t# return the result\n",
    "\tresult = [(metadata[i][\"recipe_info\"], dist) for i, dist in zip(stored_indices, stored_distances) if 0<= i < len(metadata)\n",
    "\t]\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the retrival system\n",
    "query = \"How to make bread ?\"\n",
    "result = query_embeddings(query, index, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the results together for the generation (LLM)\n",
    "def combine_retrieved_content(results):\n",
    "\tcombined_content = \"\\n\\n\".join([result[0] for result in results])\n",
    "\treturn combined_content\n",
    "\t\n",
    "combine_content = combine_retrieved_content(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system prompt\n",
    "system_prompt = f\"\"\"\n",
    "You are a highly experience and expert chef specialized in providing cooking advice.\n",
    "Your main task is to provide information precise and accurate on the combined content.\n",
    "You answer directly to the query using only information from the provided {combine_content}.\n",
    "If you do not know the answer, just say that you do not know.\n",
    "Your goal is to help the user answer the query: {query}.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to retrieve from the API\n",
    "def generate_response(query, combined_content, system_prompt):\n",
    "\tresponse = client.chat.completions.create(\n",
    "\t\tmodel = MODEL,\n",
    "\t\tmessages = [\n",
    "\t\t\t{\"role\":\"system\", \"content\":system_prompt},\n",
    "\t\t\t{\"role\":\"user\",\"content\": query},\n",
    "\t\t\t{\"role\":\"assistant\", \"content\":combined_content}\n",
    "\t\t],\n",
    "\t\ttemperature = 0\n",
    "\t)\n",
    "\treturn response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the results\n",
    "answer = generate_response(query=query, combined_content=combine_content, system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To make bread, you can follow one of these recipes:\n",
       "\n",
       "### 1. Bannocks\n",
       "**Ingredients:**\n",
       "- 1 Cupful of Thick Sour Milk\n",
       "- ½ Cupful of Sugar\n",
       "- 1 Egg\n",
       "- 2 Cupfuls of Flour\n",
       "- ½ Cupful of Indian Meal\n",
       "- 1 Teaspoonful of Soda\n",
       "- A pinch of Salt\n",
       "\n",
       "**Instructions:**\n",
       "1. Make the mixture stiff enough to drop from a spoon.\n",
       "2. Drop mixture, size of a walnut, into boiling fat.\n",
       "3. Serve warm, with maple syrup.\n",
       "\n",
       "---\n",
       "\n",
       "### 2. Boston Brown Bread\n",
       "**Ingredients:**\n",
       "- 1 Cupful of Rye Meal\n",
       "- 1 Cupful of Graham Meal\n",
       "- ½ Cupful of Flour\n",
       "- 1 Cupful of Indian Meal\n",
       "- 1 Cupful of Sweet Milk\n",
       "- 1 Cupful of Sour Milk\n",
       "- 1 Cupful of Molasses\n",
       "- ½ Teaspoonful of Salt\n",
       "- 1 Heaping Teaspoonful of Soda\n",
       "\n",
       "**Instructions:**\n",
       "1. Stir the meals and salt together.\n",
       "2. Beat the soda into the molasses until it foams.\n",
       "3. Add sour milk, mix all together, and pour into a well-greased tin pail.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Nut Bread\n",
       "**Ingredients:**\n",
       "- 2½ Cupfuls of Flour\n",
       "- 3 Teaspoonfuls of Baking Powder\n",
       "- ¼ Teaspoonful of Salt\n",
       "- ½ Cupful of Sugar\n",
       "- 1 Egg\n",
       "- 1 Cupful of Milk\n",
       "- ¾ Cupful of English Walnut Meats, chopped fine\n",
       "\n",
       "**Instructions:**\n",
       "1. Beat egg and sugar together, then add milk and salt.\n",
       "2. Sift the baking powder into the dry flour.\n",
       "3. Combine all ingredients together, adding the nuts last while covering with a little flour to prevent falling.\n",
       "4. Bake in a moderate oven for one hour.\n",
       "\n",
       "---\n",
       "\n",
       "### 4. Oatmeal Bread\n",
       "**Ingredients:**\n",
       "- 2 Cupfuls of Rolled Oats\n",
       "- 3½ Cupfuls of Boiling Water\n",
       "- ½ Cupful of Molasses\n",
       "- 1 Yeast Cake\n",
       "- Pinch of Salt\n",
       "- Flour (enough to make a stiff dough)\n",
       "\n",
       "**Instructions:**\n",
       "1. Let the rolled oats and boiling water stand until cool.\n",
       "2. Add the molasses, salt, and yeast cake (dissolved in cold water).\n",
       "3. Stir in flour enough to make a stiff dough.\n",
       "4. Let it rise overnight, then mold into loaves and let rise again.\n",
       "5. Bake for forty-five minutes in a moderate oven.\n",
       "\n",
       "---\n",
       "\n",
       "### 5. Parker House Rolls\n",
       "**Ingredients:**\n",
       "- 1 Quart of Flour\n",
       "- 1 Tablespoon of Lard\n",
       "- 3 Tablespoons of Sugar\n",
       "- ½ Teaspoon of Salt\n",
       "- ½ Pint of Milk\n",
       "- 1 Yeast Cake (dissolved in ½ cup of cold water)\n",
       "\n",
       "**Instructions:**\n",
       "1. Scald the milk. When nearly cold, add the yeast cake dissolved in cold water.\n",
       "2. Rub the lard, sugar, and salt into the flour.\n",
       "3. Stir all together with a knife and knead.\n",
       "4. Let rise to twice its bulk and knead again.\n",
       "5. Roll half an inch thick, cut into rounds, spread with butter, and double over.\n",
       "6. Let rise again and bake for twenty minutes in a hot oven.\n",
       "\n",
       "Choose any of these recipes to make your bread!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine retriever and generation to get the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_system(query, index, metadata, system_prompt, k=5):\n",
    "\t# Retrival system\n",
    "\tresults = query_embeddings(query, index, metadata, k)\n",
    "\t# Content merge\n",
    "\tcombined_contents = combine_retrieved_content(results)\n",
    "\t# Genaration\n",
    "\tresponse =  generate_response(query, combined_contents, system_prompt)\n",
    "\t\n",
    "\treturn response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2  = \"I want something Vegan?\"\n",
    "answer2 = rag_system(query=query2, index=index, metadata=metadata, system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The recipes provided are not specifically vegan, as they include ingredients like eggs, milk, and butter. However, you can modify some of the recipes to make them vegan-friendly by substituting animal products with plant-based alternatives. Here are some suggestions:\n",
       "\n",
       "1. **Bannocks**: \n",
       "   - Substitute the egg with a flaxseed meal or chia seed mixture (1 tablespoon of flaxseed or chia seeds mixed with 2.5 tablespoons of water, let sit until it thickens).\n",
       "   - Use a plant-based milk instead of sour milk.\n",
       "\n",
       "2. **Boston Brown Bread**: \n",
       "   - Replace the egg with a flaxseed or chia seed mixture as mentioned above.\n",
       "   - Use plant-based milk and ensure the molasses is vegan.\n",
       "\n",
       "3. **Nut Bread**: \n",
       "   - Substitute the egg with a flaxseed or chia seed mixture.\n",
       "   - Use plant-based milk.\n",
       "\n",
       "4. **Oatmeal Bread**: \n",
       "   - This recipe can be made vegan by using plant-based milk and ensuring the yeast is vegan-friendly.\n",
       "\n",
       "5. **Parker House Rolls**: \n",
       "   - Replace the lard with a vegan butter or coconut oil.\n",
       "   - Use plant-based milk.\n",
       "\n",
       "6. **Popovers**: \n",
       "   - This recipe is challenging to make vegan due to the nature of popovers, but you can experiment with a combination of aquafaba (chickpea water) and plant-based milk to create a similar texture.\n",
       "\n",
       "If you need a specific vegan bread recipe, I can help create one based on common vegan ingredients. Let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(answer2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
